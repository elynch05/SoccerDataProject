import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Load the dataset to see the first few rows and understand its structure
df = pd.read_csv('/Users/elliotlynch/Desktop/VSCode/2022-2023 Football Player Stats.csv', encoding='ISO-8859-1', delimiter=';')
df.head()

#EDA
sns.histplot(df['Age'], bins=20, kde=True)
plt.title('Age Distribution of Players')
plt.xlabel('Age')
plt.ylabel('Count')
plt.show()

#Average Goals Scored by Players
average_goals = df['Goals'].mean()
print(f"The average number of goals scored by players in the dataset is: {average_goals:.2f}")

# For the purpose of this demonstration, let's focus on a simple model predicting Goals based on Shots and Assists
features = ['Shots', 'Assists']
target = 'Goals'

# Preparing the data
# Drop rows with missing values for simplicity
df_clean = df.dropna(subset=features + [target])

X = df_clean[features]
y = df_clean[target]

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initializing and training the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predicting on the test set
y_pred = model.predict(X_test)

# Evaluating the model
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error of the model: {mse:.2f}")

# Adding a new feature: 'ShotsPerGoal'
df_clean['ShotsPerGoal'] = df_clean['Shots'] / df_clean['Goals'].replace(0, 1)  # Avoid division by zero

# Updating our features list
features = ['Shots', 'Assists', 'ShotsPerGoal']

#Trying a more advanced model
from sklearn.ensemble import RandomForestRegressor

# Prepare the data with the new feature
X = df_clean[features].fillna(0)  # Simple strategy to handle any remaining missing values
y = df_clean[target].fillna(0)

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict and evaluate
y_pred_rf = rf_model.predict(X_test)
mse_rf = mean_squared_error(y_test, y_pred_rf)
print(f"Random Forest Model MSE: {mse_rf:.2f}")

from sklearn.model_selection import cross_val_score

# Using cross-validation to assess model performance
cv_scores_rf = cross_val_score(rf_model, X, y, cv=5, scoring='neg_mean_squared_error')
cv_mse_rf = -cv_scores_rf.mean()
print(f"Cross-Validated MSE for Random Forest: {cv_mse_rf:.2f}")

from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
}

# Initialize the grid search
grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best parameters and corresponding MSE
best_params = grid_search.best_params_
best_score = -grid_search.best_score_
print(f"Best Parameters: {best_params}")
print(f"Best Cross-Validated MSE: {best_score:.2f}")

#Feature Importance Analysis with Random Forest
# Extract feature importance
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]
feature_names = X.columns

# Plot the feature importances
plt.figure(figsize=(10, 6))
plt.title("Feature Importance")
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), feature_names[indices], rotation=45)
plt.xlim([-1, X.shape[1]])
plt.show()

#Model Interpretability with SHAP Values
import shap

# Initialize the SHAP Explainer
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test)

# Plot the SHAP values for the first prediction
shap.initjs() # Initialize JavaScript in Jupyter for SHAP plots
shap.force_plot(explainer.expected_value, shap_values[0,:], X_test.iloc[0,:])


shap.summary_plot(shap_values, X_test, plot_type="bar")


